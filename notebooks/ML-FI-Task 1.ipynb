{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08cd8e1-e0bb-43b3-bc91-c6750c350ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "   Row ID        Order ID Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156 2016-11-08  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156 2016-11-08  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688 2016-06-12   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966 2015-10-11  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966 2015-10-11  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'F:\\Yatharth Joshi\\ML FI TASK 1\\Sample - Superstore.csv',encoding='cp1252')\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "print(\"Data loaded successfully!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3466042-df46-4780-93f6-7d88d6ea3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order Date     Sales\n",
      "0 2014-01-03    16.448\n",
      "1 2014-01-04   288.060\n",
      "2 2014-01-05    19.536\n",
      "3 2014-01-06  4407.100\n",
      "4 2014-01-07    87.158\n"
     ]
    }
   ],
   "source": [
    "daily_sales = df.groupby('Order Date')['Sales'].sum().reset_index()\n",
    "print(daily_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24494574-2637-4a34-bf8d-e7b70a0af340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after renaming: Index(['ds', 'y'], dtype='object')\n",
      "Data head after renaming:\n",
      "          ds         y\n",
      "0 2014-01-03    16.448\n",
      "1 2014-01-04   288.060\n",
      "2 2014-01-05    19.536\n",
      "3 2014-01-06  4407.100\n",
      "4 2014-01-07    87.158\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef0113f-bd95-449e-b4a6-1ec6aad3ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1, Step 4 completed without warnings. File 'monthly_region_sales.csv' exported.\n",
      "        Date   Region  Actual Sales\n",
      "0 2014-01-31  Central      1539.906\n",
      "1 2014-01-31     East       436.174\n",
      "2 2014-01-31    South      9322.092\n",
      "3 2014-01-31     West      2938.723\n",
      "4 2014-02-28  Central      1233.174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Assuming 'df' is your loaded and cleaned DataFrame\n",
    "\n",
    "# 4. Categorical Data Aggregation (For Power BI Filters)\n",
    "# Action: Create a separate, aggregated table that keeps categorical dimensions \n",
    "# (like Region, Category) along with the monthly sales.\n",
    "\n",
    "# Replace 'M' with 'ME' to fix the FutureWarning\n",
    "monthly_region_sales = df.groupby(\n",
    "    [pd.Grouper(key='Order Date', freq='ME'), 'Region'] # <- Change 'M' to 'ME'\n",
    ")['Sales'].sum().reset_index()\n",
    "\n",
    "monthly_region_sales.rename(columns={'Order Date': 'Date', 'Sales': 'Actual Sales'}, inplace=True)\n",
    "monthly_region_sales.to_csv('monthly_region_sales.csv', index=False)\n",
    "\n",
    "print(\"Phase 1, Step 4 completed without warnings. File 'monthly_region_sales.csv' exported.\")\n",
    "print(monthly_region_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63a7a67-bee5-42ed-9ee7-1cad6cbe9c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:24:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet model successfully fit to data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "# Initialize Prophet\n",
    "m = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "\n",
    "# Fit the model (This will now work!)\n",
    "m.fit(daily_sales)\n",
    "\n",
    "print(\"Prophet model successfully fit to data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e904496-1a83-4c6e-a282-bb1b2e0741cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ds         yhat   yhat_lower   yhat_upper\n",
      "1407 2018-06-19  1466.584709 -1227.438661  4271.743327\n",
      "1408 2018-06-20   363.554653 -2435.275641  2876.468410\n",
      "1409 2018-06-21  2091.999399  -611.455780  4790.201886\n",
      "1410 2018-06-22  2474.179018  -187.403904  5380.596448\n",
      "1411 2018-06-23  1894.296058  -799.873540  4561.913878\n",
      "1412 2018-06-24  2151.785777  -622.657431  4980.873205\n",
      "1413 2018-06-25  2393.299019  -464.300789  5040.741735\n",
      "1414 2018-06-26  1430.374990 -1383.988544  4163.410084\n",
      "1415 2018-06-27   336.797810 -2263.235441  3209.779814\n",
      "1416 2018-06-28  2080.236751  -577.679220  4572.873720\n"
     ]
    }
   ],
   "source": [
    "# Create 180 future periods (days)\n",
    "future = m.make_future_dataframe(periods=180)\n",
    "# Generate the forecast (yhat is the prediction)\n",
    "forecast = m.predict(future)\n",
    "\n",
    "# To specifically see the new 180 future predictions:\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "399aeabe-f114-483e-b66e-8c19707fb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key columns from forecast\n",
    "final_forecast_data = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "# Merge with actual historical data\n",
    "combined_df = final_forecast_data.merge(daily_sales, on='ds', how='left')\n",
    "\n",
    "# Create the 'Data Type' flag (Actual or Forecast)\n",
    "combined_df['Data Type'] = combined_df['y'].apply(lambda x: 'Actual' if pd.notna(x) else 'Forecast')\n",
    "\n",
    "# Fill NaN values in 'y' with the forecast for a seamless line\n",
    "combined_df['Sales Value'] = combined_df['y'].fillna(combined_df['yhat'])\n",
    "\n",
    "# Export the final file\n",
    "combined_df.to_csv('final_sales_forecast.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91438583-14a6-4caf-b980-a3ef6d563d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
